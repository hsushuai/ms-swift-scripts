{
  "model": "/data01/LLM_model/Qwen3-30B-A3B",
  "model_type": "qwen3_moe",
  "model_revision": null,
  "task_type": "causal_lm",
  "torch_dtype": "bfloat16",
  "attn_impl": null,
  "num_labels": null,
  "problem_type": null,
  "rope_scaling": null,
  "device_map": null,
  "max_memory": {},
  "local_repo_path": null,
  "init_strategy": null,
  "template": "qwen3",
  "system": null,
  "max_length": 4000,
  "truncation_strategy": "delete",
  "max_pixels": null,
  "agent_template": null,
  "norm_bbox": null,
  "use_chat_template": true,
  "padding_free": false,
  "padding_side": "right",
  "loss_scale": "default",
  "sequence_parallel_size": 1,
  "response_prefix": null,
  "template_backend": "swift",
  "dataset": [
    "/data01/xushuai/code/data/agent-10/brain_0526.jsonl"
  ],
  "val_dataset": [],
  "split_dataset_ratio": 0.0,
  "data_seed": 42,
  "dataset_num_proc": 16,
  "load_from_cache_file": true,
  "dataset_shuffle": true,
  "val_dataset_shuffle": false,
  "streaming": false,
  "interleave_prob": null,
  "stopping_strategy": "first_exhausted",
  "shuffle_buffer_size": 1000,
  "download_mode": "reuse_dataset_if_exists",
  "columns": {},
  "strict": false,
  "remove_unused_columns": true,
  "model_name": [
    null,
    null
  ],
  "model_author": [
    null,
    null
  ],
  "custom_dataset_info": [],
  "quant_method": null,
  "quant_bits": null,
  "hqq_axis": null,
  "bnb_4bit_compute_dtype": "bfloat16",
  "bnb_4bit_quant_type": "nf4",
  "bnb_4bit_use_double_quant": true,
  "bnb_4bit_quant_storage": null,
  "max_new_tokens": null,
  "temperature": null,
  "top_k": null,
  "top_p": null,
  "repetition_penalty": null,
  "num_beams": 1,
  "stream": false,
  "stop_words": [],
  "logprobs": false,
  "top_logprobs": null,
  "ckpt_dir": "/data01/LLM_model/Qwen3-30B-A3B-mcore",
  "lora_modules": [],
  "tuner_backend": "peft",
  "train_type": "lora",
  "adapters": [],
  "external_plugins": [],
  "seed": 42,
  "model_kwargs": {},
  "load_args": true,
  "load_data_args": false,
  "use_hf": false,
  "hub_token": null,
  "custom_register_path": [],
  "ddp_timeout": 18000000,
  "ddp_backend": null,
  "ignore_args_error": false,
  "use_swift_lora": false,
  "padded_vocab_size": 151936,
  "dataloader_persistent_workers": true,
  "dataloader_prefetch_factor": 10,
  "max_epochs": null,
  "micro_batch_size": 32,
  "global_batch_size": 320,
  "recompute_granularity": "full",
  "recompute_method": "uniform",
  "recompute_num_layers": 12,
  "recompute_modules": [
    "core_attn"
  ],
  "use_cpu_initialization": false,
  "deterministic_mode": false,
  "train_iters": 208,
  "log_interval": 1,
  "tensorboard_dir": "/data01/xushuai/code/test/agent/agent_30b_v10/megatron_output/runs",
  "no_masked_softmax_fusion": false,
  "no_bias_dropout_fusion": false,
  "no_bias_swiglu_fusion": false,
  "no_rope_fusion": false,
  "no_gradient_accumulation_fusion": false,
  "cross_entropy_loss_fusion": true,
  "calculate_per_token_loss": true,
  "use_flash_attn": true,
  "attention_backend": "auto",
  "optimizer": "adam",
  "dataloader_type": "cyclic",
  "manual_gc": false,
  "manual_gc_interval": 0,
  "lr": 1e-05,
  "lr_decay_style": "cosine",
  "lr_decay_iters": null,
  "lr_warmup_iters": 20,
  "min_lr": 0.0,
  "weight_decay": 0.1,
  "clip_grad": 1.0,
  "adam_beta1": 0.9,
  "adam_beta2": 0.95,
  "adam_eps": 1e-08,
  "sgd_momentum": 0.9,
  "save": "/data01/xushuai/code/test/agent/agent_30b_v10/megatron_output",
  "save_interval": 208,
  "no_save_optim": true,
  "no_save_rng": true,
  "load": "/data01/LLM_model/Qwen3-30B-A3B-mcore",
  "no_load_optim": false,
  "no_load_rng": false,
  "finetune": true,
  "ckpt_format": "torch_dist",
  "no_initialization": true,
  "auto_detect_ckpt_format": true,
  "exit_on_missing_checkpoint": true,
  "distributed_backend": "nccl",
  "use_distributed_optimizer": true,
  "tensor_model_parallel_size": 4,
  "pipeline_model_parallel_size": 1,
  "decoder_first_pipeline_num_layers": null,
  "decoder_last_pipeline_num_layers": null,
  "sequence_parallel": true,
  "context_parallel_size": 1,
  "tp_comm_overlap": true,
  "overlap_grad_reduce": true,
  "overlap_param_gather": true,
  "distributed_timeout_minutes": 300000,
  "num_layers": 48,
  "hidden_size": 2048,
  "ffn_hidden_size": 768,
  "num_attention_heads": 32,
  "group_query_attention": true,
  "num_query_groups": 4,
  "max_position_embeddings": 40960,
  "position_embedding_type": "rope",
  "rotary_base": 1000000,
  "rotary_percent": 1.0,
  "normalization": "RMSNorm",
  "norm_epsilon": 1e-06,
  "swiglu": true,
  "untie_embeddings_and_output_weights": true,
  "disable_bias_linear": true,
  "add_qkv_bias": false,
  "attention_dropout": 0.0,
  "hidden_dropout": 0.0,
  "kv_channels": 128,
  "qk_layernorm": true,
  "transformer_impl": "transformer_engine",
  "num_experts": 128,
  "moe_ffn_hidden_size": 768,
  "moe_shared_expert_intermediate_size": null,
  "moe_router_topk": 8,
  "moe_router_pre_softmax": false,
  "moe_aux_loss_coeff": 0.01,
  "expert_model_parallel_size": 2,
  "moe_token_dispatcher_type": null,
  "moe_grouped_gemm": true,
  "moe_router_load_balancing_type": "aux_loss",
  "moe_z_loss_coeff": null,
  "moe_expert_capacity_factor": 1.0,
  "moe_shared_expert_overlap": true,
  "moe_layer_recompute": false,
  "fp16": false,
  "bf16": true,
  "apply_query_key_layer_scaling": false,
  "attention_softmax_in_fp32": true,
  "log_params_norm": false,
  "log_throughput": true,
  "tensorboard_log_interval": 1,
  "tensorboard_queue_size": 50,
  "log_timers_to_tensorboard": true,
  "no_log_learning_rate_to_tensorboard": false,
  "log_validation_ppl_to_tensorboard": true,
  "log_memory_to_tensorboard": true,
  "logging_level": null,
  "wandb_project": null,
  "wandb_exp_name": null,
  "wandb_save_dir": null,
  "eval_iters": 100,
  "eval_interval": 208,
  "seq_length": 4000,
  "num_workers": 16,
  "no_create_attention_mask_in_dataloader": true,
  "extra_megatron_kwargs": {},
  "add_version": false,
  "lazy_tokenize": false,
  "packing": true,
  "rank": 0,
  "local_rank": 0,
  "global_world_size": 8,
  "local_world_size": 8,
  "model_suffix": "Qwen3-30B-A3B",
  "model_info": "ModelInfo(model_type='qwen3_moe', model_dir='/data01/LLM_model/Qwen3-30B-A3B', torch_dtype=torch.bfloat16, max_model_len=40960, quant_method=None, quant_bits=None, rope_scaling=None, config=None, task_type='causal_lm', num_labels=None)",
  "model_meta": "ModelMeta(model_type='qwen3_moe', model_groups=[ModelGroup(models=[Model(ms_model_id='Qwen/Qwen3-30B-A3B-Base', hf_model_id='Qwen/Qwen3-30B-A3B-Base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen3-235B-A22B-Base', hf_model_id='Qwen/Qwen3-235B-A22B-Base', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen3-30B-A3B', hf_model_id='Qwen/Qwen3-30B-A3B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen3-235B-A22B', hf_model_id='Qwen/Qwen3-235B-A22B', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen3-30B-A3B-FP8', hf_model_id='Qwen/Qwen3-30B-A3B-FP8', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='Qwen/Qwen3-235B-A22B-FP8', hf_model_id='Qwen/Qwen3-235B-A22B-FP8', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Qwen3-30B-A3B-AWQ', hf_model_id='cognitivecomputations/Qwen3-30B-A3B-AWQ', model_path=None, ms_revision=None, hf_revision=None), Model(ms_model_id='swift/Qwen3-235B-A22B-AWQ', hf_model_id='cognitivecomputations/Qwen3-235B-A22B-AWQ', model_path=None, ms_revision=None, hf_revision=None)], ignore_patterns=None, requires=None, tags=[])], template='qwen3', get_function=<function get_model_tokenizer_with_flash_attn at 0x7f1d3f214c20>, model_arch=None, architectures=['Qwen3MoeForCausalLM'], additional_saved_files=[], torch_dtype=None, is_multimodal=False, is_reward=False, task_type=None, ignore_patterns=None, requires=['transformers>=4.51'], tags=[])",
  "model_dir": "/data01/LLM_model/Qwen3-30B-A3B",
  "hub": "<class 'swift.hub.hub.MSHub'>",
  "megatron_model_meta": "MegatronModelMeta(megatron_model_type='gpt', model_types=['qwen2', 'qwen2_5', 'qwq', 'qwq_preview', 'qwen2_5_math', 'llama', 'llama3', 'llama3_1', 'llama3_2', 'longwriter_llama3_1', 'codefuse_codellama', 'marco_o1', 'deepseek', 'deepseek_r1_distill', 'yi', 'yi_coder', 'sus', 'skywork_o1', 'openbuddy_llama', 'openbuddy_llama3', 'megrez', 'reflection', 'numina', 'ziya', 'mengzi3', 'qwen3', 'qwen2_moe', 'qwen3_moe'], model_provider=<function model_provider at 0x7f1d206d9bc0>, convert_hf_config=<function convert_gpt_hf_config at 0x7f1d206d9260>, convert_mcore2hf=<function convert_mcore2hf at 0x7f1d206d9b20>, convert_hf2mcore=<function convert_hf2mcore at 0x7f1d206d9760>, extra_args_provider=None)",
  "extra_args": {
    "model": "/data01/LLM_model/Qwen3-30B-A3B",
    "model_type": "qwen3_moe",
    "model_revision": null,
    "task_type": "causal_lm",
    "torch_dtype": "bfloat16",
    "attn_impl": null,
    "num_labels": null,
    "problem_type": null,
    "rope_scaling": null,
    "device_map": null,
    "max_memory": {},
    "local_repo_path": null,
    "init_strategy": null,
    "template": "qwen3",
    "system": null,
    "max_length": 4000,
    "truncation_strategy": "delete",
    "max_pixels": null,
    "agent_template": null,
    "norm_bbox": null,
    "use_chat_template": true,
    "padding_free": false,
    "padding_side": "right",
    "sequence_parallel_size": 1,
    "response_prefix": null,
    "template_backend": "swift",
    "dataset": [
      "/data01/xushuai/code/data/agent-10/brain_0526.jsonl"
    ],
    "val_dataset": [],
    "split_dataset_ratio": 0.0,
    "data_seed": 42,
    "dataset_num_proc": 16,
    "load_from_cache_file": true,
    "dataset_shuffle": true,
    "val_dataset_shuffle": false,
    "streaming": false,
    "interleave_prob": null,
    "stopping_strategy": "first_exhausted",
    "shuffle_buffer_size": 1000,
    "download_mode": "reuse_dataset_if_exists",
    "columns": {},
    "strict": false,
    "remove_unused_columns": true,
    "model_name": [
      null,
      null
    ],
    "model_author": [
      null,
      null
    ],
    "custom_dataset_info": [],
    "quant_method": null,
    "quant_bits": null,
    "hqq_axis": null,
    "bnb_4bit_compute_dtype": "bfloat16",
    "bnb_4bit_quant_type": "nf4",
    "bnb_4bit_use_double_quant": true,
    "bnb_4bit_quant_storage": null,
    "max_new_tokens": null,
    "temperature": null,
    "top_k": null,
    "top_p": null,
    "repetition_penalty": null,
    "num_beams": 1,
    "stream": false,
    "stop_words": [],
    "logprobs": false,
    "top_logprobs": null,
    "ckpt_dir": "/data01/LLM_model/Qwen3-30B-A3B-mcore",
    "lora_modules": [],
    "tuner_backend": "peft",
    "train_type": "lora",
    "adapters": [],
    "external_plugins": [],
    "model_kwargs": {},
    "load_args": true,
    "load_data_args": false,
    "use_hf": false,
    "hub_token": null,
    "custom_register_path": [],
    "ddp_timeout": 18000000,
    "ddp_backend": null,
    "ignore_args_error": false,
    "use_swift_lora": false,
    "padded_vocab_size": 151936,
    "dataloader_persistent_workers": true,
    "dataloader_prefetch_factor": 10,
    "max_epochs": null,
    "add_version": false,
    "lazy_tokenize": false,
    "packing": true
  }
}